\documentclass[fyp]{socreport}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx} % to insert images
\usepackage{float}
%%% code block setups
\usepackage[newfloat]{minted}
\usepackage{xcolor} % to access the named colour LightGray
\definecolor{LightGray}{gray}{0.9}
\usepackage{caption}
\newenvironment{code}{\captionsetup{type=listing}}{}
\SetupFloatingEnvironment{listing}{name=Code}
%%% code block setups
\usepackage{fullpage}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{amsmath}
% \usepackage{tocbibind}
\interfootnotelinepenalty=10000 %% Completely prevent breaking of footnotes

\begin{document}
\pagenumbering{roman}
\title{Competition Platform for AI Tasks}
\author{Tan Yuanhong}
\projyear{2021/22}
\projnumber{H247080}
\advisor{Dr. Akshay Narayan, Prof. Leong Tze Yun}
\deliverables{
	\item Report: 1 Volume
% 	\item Source Code: 6 Git Repository
}
\maketitle
\begin{abstract}
Entering the second decade of the 21st century, machine learning and artificial intelligence is the new must-have for computer science education. However, while the data-oriented tasks like classification and regression have well-adopted platforms such as Kaggle, simulation-oriented tasks that are most common for reinforcement learning (RL) algorithms are yet to have a feature-complete online judging solution. This project aims to build a complete solution that is extensible, scalable, and easy-to-use. It covers four critical components of judging RL algorithms: a simulation environment framework, an auto-grading framework, a scalable and secure sandbox for arbitrary code execution, and finally a modern web application as the entry point. Besides a comprehensive documentation and many quality-of-life new features, this project greatly improves the performance over existing internal platform (aiVLE 1.0) with a task queue system that not only distributes tasks fairly, but also dynamically adapts to the load of each worker node thanks to its resource awareness. Experimental results show that the new system provides equal task distribution among worker nodes and nearly three times of resource utilization improvement over aiVLE 1.0 ($>90\%$ vs $\approx 30\%$).

\begin{project-nature}
	Implementation, Experimentation, Simulation
\end{project-nature}
\begin{keywords}
    \item Artificial Intelligence
	\item Machine Learning
\end{keywords}
\begin{implement}
	Ubuntu 20.04, Firejail 0.9.68, Python 3.8, Django 4.0, Celery 5.2
\end{implement}

\end{abstract}

\begin{acknowledgement}
I would like to thank my friends and family for their support during the hard times of the COVID-19 pandemic, especially my significant other for her patiently listening to my annoyingly frequent mentions of this project.\\
I would also like to thank my advisors Dr. Narayan and Prof. Leong. They offered an unimaginable amount of guidance to this final year project with great kindness.\\
Without them, this project would not have been possible.\\
\end{acknowledgement}

\listoffigures 
\listoftables
\tableofcontents

\include{ch-introduction}
\include{ch-project_objective}
\include{ch-design_and_impl}
\include{ch-deployment_and_testing}
\include{ch-conclusion}

\bibliographystyle{socreport}
\bibliography{socreport}

\appendix
\include{appendix-list_of_links}
\include{appendix-aivle_gym}
\include{appendix-aivle_worker}
\include{appendix-aivle_web}

% \chapter{Proofs}
% In this appendix, we present alternate, longer, but more interesting proof 
% of correctness of our algorithm.  This proof is based on induction and proof
% by contradiction.
\end{document}
